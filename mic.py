# mic_bridge_with_stt.py
import asyncio
import websockets
import numpy as np
import sounddevice as sd
import threading
import time
import os
import wave
import queue
import speech_recognition as sr
from io import BytesIO

# ========================
#  C·∫§U H√åNH
# ========================
SAMPLE_RATE = 48000
CHANNELS = 1
BUFFER_SIZE = int(os.getenv('MIC_BRIDGE_BUFFER', '512'))
VERBOSE = os.getenv('MIC_BRIDGE_VERBOSE', '1') == '1'
ENABLE_STT = True  # B·∫≠t Speech-to-Text
STT_CHUNK_SECONDS = 3  # Nh·∫≠n d·∫°ng m·ªói 3 gi√¢y

# Queue cho audio playback v√† STT
audio_queue = queue.Queue(maxsize=10)
stt_queue = queue.Queue(maxsize=5)

# Bi·∫øn to√†n c·ª•c
last_print_time = time.time()
is_playing = False
recognizer = sr.Recognizer()

# ========================
#  T√åM VB-CABLE
# ========================
def find_vb_cable():
    devices = sd.query_devices()
    for i, d in enumerate(devices):
        name = d['name'].lower()
        if 'cable input' in name and d['max_output_channels'] > 0:
            return i
    return None

DEVICE_ID = find_vb_cable()
if DEVICE_ID is None:
    print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y VB-CABLE, s·ª≠ d·ª•ng thi·∫øt b·ªã m·∫∑c ƒë·ªãnh")
    DEVICE_ID = sd.default.device[1]

device_name = sd.query_devices(DEVICE_ID)['name']
print(f"‚úÖ ƒê√£ ch·ªçn: [{DEVICE_ID}] {device_name}\n")

# ========================
#  T·ªêI ∆ØU √ÇM THANH
# ========================
def optimize_audio_quality(audio_data):
    audio_data = audio_data.astype(np.float32)
    max_val = np.max(np.abs(audio_data))
    
    if max_val < 0.05:
        audio_data = np.clip(audio_data * 4.0, -1.0, 1.0)
    elif max_val < 0.15:
        audio_data = np.clip(audio_data * 2.5, -1.0, 1.0)
    elif max_val < 0.4:
        audio_data = np.clip(audio_data * 1.3, -1.0, 1.0)
    
    new_max = np.max(np.abs(audio_data))
    if new_max > 0.01 and new_max < 0.7:
        target_max = 0.75
        audio_data = np.clip(audio_data * (target_max / new_max), -1.0, 1.0)
    
    return audio_data

# ========================
#  SPEECH-TO-TEXT WORKER
# ========================
def stt_worker():
    """Thread x·ª≠ l√Ω Speech Recognition"""
    print("üéØ Speech-to-Text worker started...")
    accumulated_audio = []
    accumulated_samples = 0
    target_samples = SAMPLE_RATE * STT_CHUNK_SECONDS
    
    while True:
        try:
            # L·∫•y audio t·ª´ STT queue
            audio_chunk = stt_queue.get()
            if audio_chunk is None:
                break
                
            accumulated_audio.append(audio_chunk)
            accumulated_samples += len(audio_chunk)
            
            # Khi ƒë·ªß audio, th·ª±c hi·ªán nh·∫≠n d·∫°ng
            if accumulated_samples >= target_samples:
                combined = np.concatenate(accumulated_audio)
                
                # Chuy·ªÉn sang int16 ƒë·ªÉ speech_recognition x·ª≠ l√Ω
                audio_int16 = (combined * 32767).astype(np.int16)
                
                # T·∫°o AudioData object
                audio_data = sr.AudioData(
                    audio_int16.tobytes(), 
                    SAMPLE_RATE, 
                    2  # 16-bit
                )
                
                try:
                    # Nh·∫≠n d·∫°ng gi·ªçng n√≥i (d√πng Google Speech Recognition - mi·ªÖn ph√≠)
                    print("üé§ ƒêang nh·∫≠n d·∫°ng gi·ªçng n√≥i...")
                    text = recognizer.recognize_google(audio_data, language='vi-VN')
                    
                    # In k·∫øt qu·∫£ v·ªõi m√†u xanh l√°
                    print(f"\n{'='*60}")
                    print(f"üìù NH·∫¨N D·∫†NG: {text}")
                    print(f"{'='*60}\n")
                    
                except sr.UnknownValueError:
                    print("‚ö†Ô∏è Kh√¥ng nghe r√µ, th·ª≠ n√≥i to h∆°n")
                except sr.RequestError as e:
                    print(f"‚ùå L·ªói API: {e}")
                except Exception as e:
                    print(f"‚ùå L·ªói STT: {e}")
                
                # Reset buffer
                accumulated_audio = []
                accumulated_samples = 0
                
        except Exception as e:
            print(f"‚ùå L·ªói STT worker: {e}")
            time.sleep(0.1)

# ========================
#  V√íNG L·∫∂P PH√ÅT √ÇM THANH
# ========================
def audio_playback_loop():
    global is_playing, last_print_time
    print("üîä B·∫Øt ƒë·∫ßu ph√°t √¢m thanh...")
    
    try:
        with sd.OutputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=np.float32,
            device=DEVICE_ID,
            blocksize=BUFFER_SIZE,
            latency='low'
        ) as stream:
            while True:
                try:
                    audio_data = audio_queue.get(timeout=0.1)
                    if audio_data is not None and len(audio_data) > 0:
                        optimized = optimize_audio_quality(audio_data)
                        audio_to_play = optimized.reshape(-1, 1)
                        
                        # Chia nh·ªè th√†nh chunks
                        chunk_size = BUFFER_SIZE
                        for i in range(0, len(audio_to_play), chunk_size):
                            chunk = audio_to_play[i:i+chunk_size]
                            if len(chunk) < chunk_size:
                                padding = np.zeros((chunk_size - len(chunk), 1), dtype=np.float32)
                                chunk = np.vstack([chunk, padding])
                            stream.write(chunk.astype(np.float32))
                        
                        is_playing = True
                        
                        # G·ª≠i audio sang STT queue
                        if ENABLE_STT:
                            try:
                                stt_queue.put_nowait(optimized.copy())
                            except queue.Full:
                                pass  # B·ªè qua n·∫øu queue ƒë·∫ßy
                        
                except queue.Empty:
                    silence = np.zeros((BUFFER_SIZE, CHANNELS), dtype=np.float32)
                    stream.write(silence)
                    is_playing = False
                    
                except Exception as e:
                    print(f"‚ùå L·ªói playback: {e}")
                    
    except Exception as e:
        print(f"‚ùå L·ªói stream: {e}")

# ========================
#  WEBSOCKET HANDLER
# ========================
async def handle_audio(websocket):
    global last_print_time
    client_addr = websocket.remote_address
    print(f"‚úÖ Client k·∫øt n·ªëi: {client_addr}")

    try:
        async for message in websocket:
            try:
                audio_data = np.frombuffer(message, dtype=np.float32)
                
                # X·ª≠ l√Ω stereo/mono
                if len(audio_data) > 0:
                    if len(audio_data) % 2 == 0:
                        left_channel = audio_data[::2]
                        right_channel = audio_data[1::2]
                        if np.max(np.abs(right_channel)) < 0.001:
                            audio_data = left_channel
                        else:
                            audio_data = left_channel
                
                if len(audio_data.shape) > 1:
                    audio_data = audio_data.flatten()
                
                # Log
                max_amplitude = np.max(np.abs(audio_data))
                if VERBOSE and time.time() - last_print_time >= 2.0:
                    status = "‚úÖ C√≥ √¢m thanh" if max_amplitude > 0.01 else "‚ö†Ô∏è Im l·∫∑ng"
                    print(f"üì• Nh·∫≠n: {len(audio_data)} m·∫´u, √¢m l∆∞·ª£ng: {max_amplitude:.4f} {status}")
                    last_print_time = time.time()

                # Th√™m v√†o queue
                try:
                    audio_queue.put_nowait(audio_data)
                except queue.Full:
                    try:
                        audio_queue.get_nowait()
                        audio_queue.put_nowait(audio_data)
                    except:
                        pass
                        
            except Exception as e:
                print(f"‚ùå L·ªói x·ª≠ l√Ω audio: {e}")
                
    except websockets.exceptions.ConnectionClosed:
        print(f"‚ö†Ô∏è Client ng·∫Øt k·∫øt n·ªëi: {client_addr}")
    except Exception as e:
        print(f"‚ùå L·ªói WebSocket: {e}")
    finally:
        while not audio_queue.empty():
            try:
                audio_queue.get_nowait()
            except:
                break

# ========================
#  MAIN SERVER
# ========================
async def main():
    # Kh·ªüi ƒë·ªông threads
    audio_thread = threading.Thread(target=audio_playback_loop, daemon=True)
    audio_thread.start()
    
    if ENABLE_STT:
        stt_thread = threading.Thread(target=stt_worker, daemon=True)
        stt_thread.start()
        print("üéØ Speech-to-Text: ƒê√É B·∫¨T (ti·∫øng Vi·ªát)\n")
    
    print(f"WebSocket Server: ws://0.0.0.0:8765")
    print(f"Ph√°t v√†o: [{DEVICE_ID}] {device_name}")
    print("M·ªü tr√¨nh duy·ªát ‚Üí k·∫øt n·ªëi t·ª´ ƒëi·ªán tho·∫°i")
    print("Ctrl+C ƒë·ªÉ d·ª´ng\n")

    async with websockets.serve(handle_audio, "0.0.0.0", 8765, ping_interval=20, ping_timeout=10):
        await asyncio.Future()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n‚õî ƒê√£ d·ª´ng server")
        stt_queue.put(None)  # Stop STT worker
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()