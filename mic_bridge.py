# mic_bridge.py - Micro Bridge Server vá»›i Speech-to-Text
import asyncio
import websockets
import numpy as np
import sounddevice as sd
import threading
import time
import os
import wave
import io
import json
from dataclasses import dataclass
from typing import Optional
from datetime import datetime, timedelta

# ========================
#  KIá»‚M TRA SPEECH-TO-TEXT
# ========================
try:
    import speech_recognition as sr
    SPEECH_RECOGNITION_AVAILABLE = True
    print("âœ… SpeechRecognition Ä‘Ã£ sáºµn sÃ ng")
except ImportError:
    SPEECH_RECOGNITION_AVAILABLE = False
    print("âŒ Speech-to-text khÃ´ng kháº£ dá»¥ng. CÃ i Ä‘áº·t: pip install SpeechRecognition pyaudio")

# ========================
#  Cáº¤U HÃŒNH
# ========================
SAMPLE_RATE = 48000
CHANNELS = 1
BUFFER_SIZE = int(os.getenv('MIC_BRIDGE_BUFFER', '256'))
VERBOSE = os.getenv('MIC_BRIDGE_VERBOSE', '1') == '1'
SAVE_INCOMING = os.getenv('MIC_BRIDGE_SAVE', '0') == '1'
SAVE_SECONDS = 4

# Timeout settings
CONNECTION_TIMEOUT = 300  # 5 phÃºt
INACTIVITY_TIMEOUT = 180  # 3 phÃºt khÃ´ng cÃ³ audio

# ========================
#  DATA CLASSES
# ========================
@dataclass
class Connection:
    websocket: websockets.WebSocketServerProtocol
    connected_at: datetime
    last_activity: datetime
    client_ip: str
    is_active: bool = True

# ========================
#  BIáº¾N TOÃ€N Cá»¤C
# ========================
current_audio_data = None
is_playing = False
audio_lock = threading.Lock()

# Quáº£n lÃ½ káº¿t ná»‘i
current_connection: Optional[Connection] = None
connection_lock = threading.Lock()

# Timeout tracking
inactivity_timer = None
connection_timer = None

# LÆ°u incoming Ä‘á»ƒ debug
_save_samples_threshold = SAVE_SECONDS * SAMPLE_RATE
_incoming_chunks = []
_save_lock = threading.Lock()
_saved_incoming = False

# Bá»™ Ä‘á»‡m vÃ  VAD cho STT
stt_lock = threading.Lock()
stt_buffer = np.array([], dtype=np.float32)
last_voice_time = time.time()
VAD_THRESHOLD = 0.02       # ngÆ°á»¡ng biÃªn Ä‘á»™ coi lÃ  nÃ³i
VAD_MIN_SPEECH_MS = 300    # tá»‘i thiá»ƒu 0.3s Ä‘á»ƒ coi lÃ  cÃ¢u nÃ³i
VAD_SILENCE_MS = 800       # khoáº£ng láº·ng 0.8s Ä‘á»ƒ cáº¯t cÃ¢u
MAX_STT_BUFFER_SECONDS = 15  # trÃ¡nh buffer quÃ¡ dÃ i

recognizer = sr.Recognizer() if SPEECH_RECOGNITION_AVAILABLE else None

# ========================
#  IN DANH SÃCH THIáº¾T Bá»Š
# ========================
print("=" * 60)
print("ğŸ“Š DANH SÃCH THIáº¾T Bá»Š Ã‚M THANH")
print("=" * 60)

for i, d in enumerate(sd.query_devices()):
    marker = " (VB-CABLE)" if 'cable' in d['name'].lower() else ""
    print(f"[{i}] {d['name']}{marker}")
    print(f"    Input: {d['max_input_channels']} | Output: {d['max_output_channels']}")

# ========================
#  CHá»ŒN VB-CABLE Tá»° Äá»˜NG
# ========================
def find_vb_cable():
    devices = sd.query_devices()
    
    # Æ¯u tiÃªn tÃ¬m VB-CABLE
    for i, d in enumerate(devices):
        name = d['name'].lower()
        if ('cable' in name or 'virtual' in name) and d['max_output_channels'] > 0:
            return i
    
    # Náº¿u khÃ´ng tÃ¬m tháº¥y, tÃ¬m thiáº¿t bá»‹ output Ä‘áº§u tiÃªn
    for i, d in enumerate(devices):
        if d['max_output_channels'] > 0:
            return i
    
    return 0

DEVICE_ID = find_vb_cable()
device_name = sd.query_devices(DEVICE_ID)['name']

print("\n" + "=" * 60)
print("ğŸ¯ THIáº¾T Bá»Š ÄÆ¯á»¢C CHá»ŒN")
print("=" * 60)
print(f"Device ID: {DEVICE_ID}")
print(f"Device: {device_name}")
print("\nğŸ“‹ HÆ¯á»šNG DáºªN:")
print(f"1. PhÃ¡t Ã¢m thanh vÃ o: {device_name}")
print(f"2. Trong Chrome/Windows: chá»n '{device_name}' lÃ m microphone")
print("=" * 60 + "\n")

# Kiá»ƒm tra thiáº¿t bá»‹ phÃ¡t
try:
    test_data = np.zeros(512, dtype=np.float32)
    sd.play(test_data, samplerate=SAMPLE_RATE, device=DEVICE_ID, blocking=False)
    sd.stop()
    print("âœ… Thiáº¿t bá»‹ Ã¢m thanh hoáº¡t Ä‘á»™ng tá»‘t\n")
except Exception as e:
    print(f"âŒ Lá»—i thiáº¿t bá»‹: {e}")
    exit(1)

# ========================
#  Tá»I Æ¯U Ã‚M THANH
# ========================
def optimize_audio_quality(audio_data):
    audio_data = audio_data.astype(np.float32)
    max_val = np.max(np.abs(audio_data)) if len(audio_data) > 0 else 0.0
    
    # TÄƒng gain náº¿u Ã¢m lÆ°á»£ng quÃ¡ nhá»
    if 0.001 < max_val < 0.1:
        gain = 1.0 / max_val
        audio_data = np.clip(audio_data * gain, -1.0, 1.0)
    
    return audio_data

# ========================
#  CHUYá»‚N BUFFER â†’ TEXT
# ========================
def buffer_to_text_and_print(buf: np.ndarray):
    if not SPEECH_RECOGNITION_AVAILABLE or buf.size == 0:
        return
    
    try:
        max_samples = int(MAX_STT_BUFFER_SECONDS * SAMPLE_RATE)
        if buf.size > max_samples:
            buf = buf[-max_samples:]

        int_data = np.clip(buf, -1.0, 1.0)
        int_data = (int_data * 32767.0).astype('<i2')
        
        wav_bytes = io.BytesIO()
        with wave.open(wav_bytes, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(SAMPLE_RATE)
            wf.writeframes(int_data.tobytes())
        wav_bytes.seek(0)

        with sr.AudioFile(wav_bytes) as source:
            audio = recognizer.record(source)
            text = recognizer.recognize_google(audio, language="vi-VN")
            
            # Gá»­i káº¿t quáº£ STT qua WebSocket
            if current_connection and current_connection.is_active:
                try:
                    stt_result = {
                        'type': 'STT_RESULT',
                        'text': text,
                        'timestamp': datetime.now().isoformat()
                    }
                    asyncio.create_task(
                        current_connection.websocket.send(json.dumps(stt_result))
                    )
                except:
                    pass
            
            print(f"ğŸ—£ï¸ [STT] {text}")
            
    except sr.UnknownValueError:
        if VERBOSE:
            print("â“ [STT] KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c giá»ng nÃ³i")
    except sr.RequestError as e:
        print(f"âŒ [STT] Lá»—i dá»‹ch vá»¥: {e}")
    except Exception as e:
        print(f"âŒ [STT] Lá»—i xá»­ lÃ½: {e}")

# ========================
#  TIMEOUT MANAGEMENT
# ========================
def reset_inactivity_timer():
    global inactivity_timer
    if inactivity_timer:
        inactivity_timer.cancel()
    
    inactivity_timer = threading.Timer(INACTIVITY_TIMEOUT, check_inactivity)
    inactivity_timer.daemon = True
    inactivity_timer.start()

def reset_connection_timer():
    global connection_timer
    if connection_timer:
        connection_timer.cancel()
    
    connection_timer = threading.Timer(CONNECTION_TIMEOUT, check_connection_timeout)
    connection_timer.daemon = True
    connection_timer.start()

def check_inactivity():
    global current_connection
    
    with connection_lock:
        if current_connection and current_connection.is_active:
            time_since_activity = (datetime.now() - current_connection.last_activity).total_seconds()
            
            if time_since_activity > INACTIVITY_TIMEOUT:
                print(f"â° Timeout khÃ´ng hoáº¡t Ä‘á»™ng sau {INACTIVITY_TIMEOUT} giÃ¢y")
                
                try:
                    asyncio.create_task(current_connection.websocket.close(1000, "Timeout khÃ´ng hoáº¡t Ä‘á»™ng"))
                except:
                    pass
                
                current_connection = None

def check_connection_timeout():
    global current_connection
    
    with connection_lock:
        if current_connection and current_connection.is_active:
            connection_duration = (datetime.now() - current_connection.connected_at).total_seconds()
            
            if connection_duration > CONNECTION_TIMEOUT:
                print(f"â° Timeout káº¿t ná»‘i sau {CONNECTION_TIMEOUT} giÃ¢y")
                
                try:
                    asyncio.create_task(current_connection.websocket.close(1000, "Timeout káº¿t ná»‘i"))
                except:
                    pass
                
                current_connection = None

# ========================
#  VÃ’NG Láº¶P PHÃT Ã‚M THANH
# ========================
def audio_playback_loop():
    global current_audio_data, is_playing
    print("â–¶ï¸ Báº¯t Ä‘áº§u phÃ¡t Ã¢m thanh...")
    
    try:
        with sd.OutputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=np.float32,
            device=DEVICE_ID,
            blocksize=BUFFER_SIZE,
            latency='low'
        ) as stream:
            print("ğŸ”Š Stream audio sáºµn sÃ ng")
            
            while True:
                with audio_lock:
                    data = current_audio_data
                    current_audio_data = None
                
                if data is not None and len(data) > 0:
                    try:
                        optimized = optimize_audio_quality(data)
                        audio_to_play = optimized.reshape(-1, 1)
                        stream.write(audio_to_play.astype(np.float32))
                        is_playing = True
                        
                        if VERBOSE:
                            max_amp = np.max(np.abs(audio_to_play))
                            print(f"ğŸ“¤ PhÃ¡t: {len(audio_to_play)} máº«u, Ã¢m lÆ°á»£ng: {max_amp:.4f}")
                    
                    except Exception as e:
                        print(f"âŒ Lá»—i phÃ¡t audio: {e}")
                        is_playing = False
                else:
                    # PhÃ¡t silence
                    silence = np.zeros((BUFFER_SIZE, CHANNELS), dtype=np.float32)
                    stream.write(silence)
                    is_playing = False
                
                time.sleep(0.001)
    
    except Exception as e:
        print(f"âŒ Lá»—i stream audio: {e}")

# ========================
#  Xá»¬ LÃ STT THEO VAD
# ========================
def stt_ingest_and_maybe_decode(audio_chunk: np.ndarray):
    global stt_buffer, last_voice_time
    
    now = time.time()
    
    with stt_lock:
        if audio_chunk.size > 0:
            stt_buffer = np.concatenate([stt_buffer, audio_chunk])
    
    # Kiá»ƒm tra hoáº¡t Ä‘á»™ng Ã¢m thanh
    amp = np.max(np.abs(audio_chunk)) if audio_chunk.size > 0 else 0.0
    
    if amp >= VAD_THRESHOLD:
        last_voice_time = now
        
        # Reset inactivity timer khi cÃ³ audio
        reset_inactivity_timer()
    
    silence_ms = (now - last_voice_time) * 1000.0
    buf_len_ms = (stt_buffer.size / SAMPLE_RATE) * 1000.0
    
    # Kiá»ƒm tra vÃ  xá»­ lÃ½ STT khi Ä‘á»§ Ä‘iá»u kiá»‡n
    if silence_ms >= VAD_SILENCE_MS and buf_len_ms >= VAD_MIN_SPEECH_MS:
        with stt_lock:
            buf = stt_buffer.copy()
            stt_buffer = np.array([], dtype=np.float32)
        
        # Xá»­ lÃ½ STT trong thread riÃªng Ä‘á»ƒ khÃ´ng block audio
        threading.Thread(target=buffer_to_text_and_print, args=(buf,), daemon=True).start()

# ========================
#  WEBSOCKET HANDLER
# ========================
async def handle_audio(websocket):
    global current_audio_data, _incoming_chunks, _saved_incoming, current_connection
    
    client_addr = f"{websocket.remote_address[0]}:{websocket.remote_address[1]}"
    print(f"\nğŸ”— Client thá»­ káº¿t ná»‘i: {client_addr}")
    
    # KIá»‚M TRA Náº¾U ÄÃƒ CÃ“ Káº¾T Ná»I - Tá»ª CHá»I NGÆ¯á»œI THá»¨ 2
    with connection_lock:
        if current_connection is not None and current_connection.is_active:
            print(f"â›” Tá»ª CHá»I: ÄÃ£ cÃ³ káº¿t ná»‘i tá»« {current_connection.client_ip}")
            print(f"   Client {client_addr} bá»‹ tá»« chá»‘i (chá»‰ cho phÃ©p 1 káº¿t ná»‘i)")
            
            try:
                await websocket.close(1008, "Chá»‰ cho phÃ©p má»™t káº¿t ná»‘i. ÄÃ£ cÃ³ ngÆ°á»i dÃ¹ng khÃ¡c.")
            except:
                pass
            
            return
        
        # CHáº¤P NHáº¬N Káº¾T Ná»I Má»šI
        current_connection = Connection(
            websocket=websocket,
            connected_at=datetime.now(),
            last_activity=datetime.now(),
            client_ip=client_addr,
            is_active=True
        )
        
        print(f"âœ… CHáº¤P NHáº¬N: Káº¿t ná»‘i tá»« {client_addr}")
        print(f"   Thá»i gian: {current_connection.connected_at.strftime('%H:%M:%S')}")
    
    # Khá»Ÿi Ä‘á»™ng timer
    reset_inactivity_timer()
    reset_connection_timer()
    
    try:
        # Gá»­i thÃ´ng bÃ¡o káº¿t ná»‘i thÃ nh cÃ´ng
        welcome_msg = {
            'type': 'CONNECTION_ACCEPTED',
            'message': 'Káº¿t ná»‘i thÃ nh cÃ´ng',
            'timestamp': datetime.now().isoformat()
        }
        await websocket.send(json.dumps(welcome_msg))
        
        print("ğŸ¤ Äang chá» nháº­n Ã¢m thanh...")
        
        async for message in websocket:
            try:
                # Cáº­p nháº­t thá»i gian hoáº¡t Ä‘á»™ng
                with connection_lock:
                    if current_connection and current_connection.is_active:
                        current_connection.last_activity = datetime.now()
                
                # Xá»­ lÃ½ audio data
                audio_data = np.frombuffer(message, dtype=np.float32)
                
                if audio_data.size > 0:
                    with audio_lock:
                        current_audio_data = audio_data
                    
                    if VERBOSE:
                        amp = np.max(np.abs(audio_data))
                        print(f"ğŸ“¡ Nháº­n tá»« {client_addr}: {len(audio_data)} máº«u, Ã¢m lÆ°á»£ng: {amp:.4f}")
                    
                    # LÆ°u debug náº¿u cáº§n
                    if SAVE_INCOMING and not _saved_incoming:
                        with _save_lock:
                            chunk = audio_data.copy()
                            _incoming_chunks.append(chunk)
                            total = sum(len(c) for c in _incoming_chunks)
                            
                            if total >= _save_samples_threshold:
                                combined = np.concatenate(_incoming_chunks)
                                combined = np.clip(combined, -1.0, 1.0)
                                int_data = (combined * 32767).astype('<i2')
                                
                                with wave.open('incoming_debug.wav', 'wb') as wf:
                                    wf.setnchannels(1)
                                    wf.setsampwidth(2)
                                    wf.setframerate(SAMPLE_RATE)
                                    wf.writeframes(int_data.tobytes())
                                
                                print("ğŸ’¾ ÄÃ£ lÆ°u: incoming_debug.wav")
                                _saved_incoming = True
                    
                    # Xá»­ lÃ½ STT
                    stt_ingest_and_maybe_decode(audio_data)
                
            except Exception as e:
                print(f"âŒ Lá»—i xá»­ lÃ½ tá»« {client_addr}: {e}")
    
    except websockets.exceptions.ConnectionClosed as e:
        print(f"\nğŸ”Œ Client ngáº¯t káº¿t ná»‘i: {client_addr}")
        print(f"   Code: {e.code}, Reason: {e.reason}")
    
    except Exception as e:
        print(f"\nâŒ Lá»—i WebSocket tá»« {client_addr}: {e}")
    
    finally:
        # Dá»n dáº¹p káº¿t ná»‘i
        with connection_lock:
            if current_connection and current_connection.websocket == websocket:
                current_connection.is_active = False
                current_connection = None
                print(f"ğŸ”„ ÄÃ£ giáº£i phÃ³ng káº¿t ná»‘i tá»« {client_addr}")
        
        # Dá»«ng timer
        if inactivity_timer:
            inactivity_timer.cancel()
        
        if connection_timer:
            connection_timer.cancel()
        
        # XÃ³a audio data
        with audio_lock:
            current_audio_data = None
        
        # Xá»­ lÃ½ STT cÃ²n láº¡i
        with stt_lock:
            buf = stt_buffer.copy()
            stt_buffer = np.array([], dtype=np.float32)
        
        if buf.size > 0:
            buffer_to_text_and_print(buf)
        
        print(f"âœ… ÄÃ£ dá»n dáº¹p hoÃ n toÃ n káº¿t ná»‘i tá»« {client_addr}\n")

# ========================
#  MAIN SERVER - PORT 8766
# ========================
async def main():
    # Khá»Ÿi Ä‘á»™ng thread phÃ¡t Ã¢m thanh
    audio_thread = threading.Thread(target=audio_playback_loop, daemon=True)
    audio_thread.start()
    time.sleep(1)  # Äá»£i thread khá»Ÿi Ä‘á»™ng
    
    print("=" * 60)
    print("ğŸ™ï¸ MIC BRIDGE SERVER - PORT 8766")
    print("=" * 60)
    print(f"ğŸŒ WebSocket Server: ws://0.0.0.0:8766")
    print(f"ğŸ”Š Output Device: [{DEVICE_ID}] {device_name}")
    print(f"â° Timeout: {CONNECTION_TIMEOUT}s káº¿t ná»‘i, {INACTIVITY_TIMEOUT}s khÃ´ng hoáº¡t Ä‘á»™ng")
    print("=" * 60)
    print("ğŸ“± Má»Ÿ trÃ¬nh duyá»‡t â†’ káº¿t ná»‘i tá»« Ä‘iá»‡n thoáº¡i")
    print("âš ï¸  Chá»‰ cho phÃ©p 1 káº¿t ná»‘i táº¡i 1 thá»i Ä‘iá»ƒm")
    print("âŒ  Äiá»‡n thoáº¡i thá»© 2 sáº½ nháº­n thÃ´ng bÃ¡o 'Káº¾T Ná»I KHÃ”NG THÃ€NH CÃ”NG'")
    print("ğŸ›‘ Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng server")
    print("=" * 60 + "\n")
    
    # Khá»Ÿi Ä‘á»™ng WebSocket server trÃªn PORT 8766
    async with websockets.serve(
        handle_audio, 
        "0.0.0.0", 
        8766,  # PORT 8766 (khÃ´ng dÃ¹ng 8765 ná»¯a)
        ping_interval=20, 
        ping_timeout=10,
        max_size=10 * 1024 * 1024
    ):
        await asyncio.Future()

# ========================
#  ENTRY POINT
# ========================
if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ÄÃ£ dá»«ng server")
        print("ğŸ‘‹ Táº¡m biá»‡t!")
    except Exception as e:
        print(f"\nâŒ Lá»—i server: {e}")
        import traceback
        traceback.print_exc()