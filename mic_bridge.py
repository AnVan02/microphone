# mic_bridge_stt.py
import asyncio
import websockets
import numpy as np
import sounddevice as sd
import threading
import time
import os
import wave
import io

# ========================
#  KIá»‚M TRA SPEECH-TO-TEXT
# ========================
try:
    import speech_recognition as sr
    SPEECH_RECOGNITION_AVAILABLE = True
    print("âœ… SpeechRecognition Ä‘Ã£ sáºµn sÃ ng")
except ImportError:
    SPEECH_RECOGNITION_AVAILABLE = False
    print("âŒ Speech-to-text khÃ´ng kháº£ dá»¥ng. CÃ i Ä‘áº·t: pip install SpeechRecognition pyaudio")

# ========================
#  Cáº¤U HÃŒNH
# ========================
SAMPLE_RATE = 48000
CHANNELS = 1
BUFFER_SIZE = int(os.getenv('MIC_BRIDGE_BUFFER', '256'))
VERBOSE = os.getenv('MIC_BRIDGE_VERBOSE', '1') == '1'
SAVE_INCOMING = os.getenv('MIC_BRIDGE_SAVE', '0') == '1'
SAVE_SECONDS = 4

# ========================
#  BIáº¾N TOÃ€N Cá»¤C
# ========================
current_audio_data = None
is_playing = False
audio_lock = threading.Lock()

# Quáº£n lÃ½ káº¿t ná»‘i
current_connection = None
connection_lock = threading.Lock()

# LÆ°u incoming Ä‘á»ƒ debug
_save_samples_threshold = SAVE_SECONDS * SAMPLE_RATE
_incoming_chunks = []
_save_lock = threading.Lock()
_saved_incoming = False

# Bá»™ Ä‘á»‡m vÃ  VAD cho STT
stt_lock = threading.Lock()
stt_buffer = np.array([], dtype=np.float32)
last_voice_time = time.time()
VAD_THRESHOLD = 0.02       # ngÆ°á»¡ng biÃªn Ä‘á»™ coi lÃ  nÃ³i
VAD_MIN_SPEECH_MS = 300    # tá»‘i thiá»ƒu 0.3s Ä‘á»ƒ coi lÃ  cÃ¢u nÃ³i
VAD_SILENCE_MS = 800       # khoáº£ng láº·ng 0.8s Ä‘á»ƒ cáº¯t cÃ¢u
MAX_STT_BUFFER_SECONDS = 15  # trÃ¡nh buffer quÃ¡ dÃ i

recognizer = sr.Recognizer() if SPEECH_RECOGNITION_AVAILABLE else None

# ========================
#  IN DANH SÃCH THIáº¾T Bá»Š
# ========================
print("ğŸ“Š Danh sÃ¡ch thiáº¿t bá»‹ Ã¢m thanh:\n")
for i, d in enumerate(sd.query_devices()):
    marker = " (VB-CABLE)" if 'cable' in d['name'].lower() else ""
    print(f"[{i}] {d['name']}{marker}")
    print(f"    Input: {d['max_input_channels']} | Output: {d['max_output_channels']}\n")

# ========================
#  CHá»ŒN VB-CABLE Tá»° Äá»˜NG
# ========================
def find_vb_cable():
    devices = sd.query_devices()
    for i, d in enumerate(devices):
        name = d['name'].lower()
        if 'cable input' in name and d['max_output_channels'] > 0:
            return i
    for i, d in enumerate(devices):
        if d['max_output_channels'] > 0:
            return i
    return 0

DEVICE_ID = find_vb_cable()
print(f"\nğŸ“‹ HÆ¯á»šNG DáºªN:")
print(f"1. PhÃ¡t Ã¢m thanh vÃ o: CABLE Input (device {DEVICE_ID})")
print(f"2. Trong Chrome/Windows: chá»n 'CABLE Output' lÃ m microphone")
print(f"ğŸ¯ ÄÃ£ chá»n: [{DEVICE_ID}] {sd.query_devices(DEVICE_ID)['name']}")

# Kiá»ƒm tra thiáº¿t bá»‹ phÃ¡t
try:
    test_data = np.zeros(512, dtype=np.float32)
    sd.play(test_data, samplerate=SAMPLE_RATE, device=DEVICE_ID, blocking=False)
    sd.stop()
    print("âœ… Thiáº¿t bá»‹ Ã¢m thanh hoáº¡t Ä‘á»™ng tá»‘t")
except Exception as e:
    print(f"âŒ Lá»—i thiáº¿t bá»‹: {e}")
    exit(1)

# ========================
#  Tá»I Æ¯U Ã‚M THANH
# ========================
def optimize_audio_quality(audio_data):
    audio_data = audio_data.astype(np.float32)
    max_val = np.max(np.abs(audio_data)) if len(audio_data) > 0 else 0.0
    if max_val < 0.1 and max_val > 0:
        audio_data = np.clip(audio_data * 2.0, -1.0, 1.0)
    return audio_data

# ========================
#  CHUYá»‚N BUFFER â†’ TEXT
# ========================
def buffer_to_text_and_print(buf: np.ndarray):
    if not SPEECH_RECOGNITION_AVAILABLE or buf.size == 0:
        return
    try:
        max_samples = int(MAX_STT_BUFFER_SECONDS * SAMPLE_RATE)
        if buf.size > max_samples:
            buf = buf[-max_samples:]

        int_data = np.clip(buf, -1.0, 1.0)
        int_data = (int_data * 32767.0).astype('<i2')
        wav_bytes = io.BytesIO()
        with wave.open(wav_bytes, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(SAMPLE_RATE)
            wf.writeframes(int_data.tobytes())
        wav_bytes.seek(0)

        with sr.AudioFile(wav_bytes) as source:
            audio = recognizer.record(source)
            text = recognizer.recognize_google(audio, language="vi-VN")
            print(f"ğŸ—£ï¸ [STT] {text}")
    except sr.UnknownValueError:
        if VERBOSE:
            print("â“ [STT] KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c")
    except sr.RequestError as e:
        print(f"âŒ [STT] Lá»—i dá»‹ch vá»¥: {e}")
    except Exception as e:
        print(f"âŒ [STT] Lá»—i xá»­ lÃ½: {e}")

# ========================
#  VÃ’NG Láº¶P PHÃT Ã‚M THANH
# ========================
def audio_playback_loop():
    global current_audio_data, is_playing
    print("â–¶ï¸ Báº¯t Ä‘áº§u phÃ¡t Ã¢m thanh vÃ o VB-CABLE...")
    try:
        with sd.OutputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=np.float32,
            device=DEVICE_ID,
            blocksize=BUFFER_SIZE,
            latency='low'
        ) as stream:
            print("ğŸ”Š Stream sáºµn sÃ ng")
            while True:
                with audio_lock:
                    data = current_audio_data
                    current_audio_data = None
                if data is not None and len(data) > 0:
                    try:
                        optimized = optimize_audio_quality(data)
                        audio_to_play = optimized.reshape(-1, 1)
                        stream.write(audio_to_play.astype(np.float32))
                        is_playing = True
                        if VERBOSE:
                            print(f"ğŸ“¤ PhÃ¡t: {len(audio_to_play)} máº«u, max: {np.max(np.abs(audio_to_play)):.4f}")
                    except Exception as e:
                        print(f"âŒ Lá»—i phÃ¡t: {e}")
                        is_playing = False
                else:
                    silence = np.zeros((BUFFER_SIZE, CHANNELS), dtype=np.float32)
                    stream.write(silence)
                    is_playing = False
                time.sleep(0.001)
    except Exception as e:
        print(f"âŒ Lá»—i stream: {e}")

# ========================
#  Xá»¬ LÃ STT THEO VAD
# ========================
def stt_ingest_and_maybe_decode(audio_chunk: np.ndarray):
    global stt_buffer, last_voice_time
    now = time.time()
    
    with stt_lock:
        if audio_chunk.size > 0:
            stt_buffer = np.concatenate([stt_buffer, audio_chunk])
    amp = np.max(np.abs(audio_chunk)) if audio_chunk.size > 0 else 0.0
    if amp >= VAD_THRESHOLD:
        last_voice_time = now
    silence_ms = (now - last_voice_time) * 1000.0
    buf_len_ms = (stt_buffer.size / SAMPLE_RATE) * 1000.0

    if silence_ms >= VAD_SILENCE_MS and buf_len_ms >= VAD_MIN_SPEECH_MS:
        with stt_lock:
            buf = stt_buffer.copy()
            stt_buffer = np.array([], dtype=np.float32)
        buffer_to_text_and_print(buf)

# ========================
#  WEBSOCKET HANDLER
# ========================
async def handle_audio(websocket):
    global current_audio_data, _incoming_chunks, _saved_incoming, current_connection
    
    client_addr = websocket.remote_address
    print(f"ğŸ”— Client thá»­ káº¿t ná»‘i: {client_addr}")
    
    # Kiá»ƒm tra náº¿u Ä‘Ã£ cÃ³ káº¿t ná»‘i
    with connection_lock:
        if current_connection is not None and current_connection.open:
            print(f"â›” Tá»ª CHá»I: ÄÃ£ cÃ³ káº¿t ná»‘i tá»« {current_connection.remote_address}")
            print(f"   Client {client_addr} bá»‹ tá»« chá»‘i (chá»‰ cho phÃ©p 1 káº¿t ná»‘i)")
            await websocket.close(1008, "Chá»‰ cho phÃ©p má»™t káº¿t ná»‘i. ÄÃ£ cÃ³ ngÆ°á»i dÃ¹ng khÃ¡c.")
            return
        
        current_connection = websocket
        print(f"âœ… CHáº¤P NHáº¬N: Káº¿t ná»‘i tá»« {client_addr}")
        print(f"   Äang chá» nháº­n Ã¢m thanh...")


    try:
        await websocket.send("CONNECTED")
        
        async for message in websocket:
            try:
                audio_data = np.frombuffer(message, dtype=np.float32)

                if VERBOSE and audio_data.size > 0:
                    print(f"ğŸ“¡ Nháº­n tá»« {client_addr}: {len(audio_data)} máº«u, Ã¢m lÆ°á»£ng: {np.max(np.abs(audio_data)):.4f}")

                with audio_lock:
                    current_audio_data = audio_data

                if SAVE_INCOMING and not _saved_incoming:
                    with _save_lock:
                        chunk = audio_data.copy()
                        _incoming_chunks.append(chunk)
                        total = sum(len(c) for c in _incoming_chunks)
                        if total >= _save_samples_threshold:
                            combined = np.concatenate(_incoming_chunks)
                            combined = np.clip(combined, -1.0, 1.0)
                            int_data = (combined * 32767).astype('<i2')
                            with wave.open('incoming_debug.wav', 'wb') as wf:
                                wf.setnchannels(1)
                                wf.setsampwidth(2)
                                wf.setframerate(SAMPLE_RATE)
                                wf.writeframes(int_data.tobytes())
                            print("ğŸ’¾ ÄÃ£ lÆ°u: incoming_debug.wav")
                            _saved_incoming = True

                stt_ingest_and_maybe_decode(audio_data)

            except Exception as e:
                print(f"âŒ Lá»—i xá»­ lÃ½ tá»« {client_addr}: {e}")
    except websockets.exceptions.ConnectionClosed as e:
        print(f"ğŸ”Œ Client ngáº¯t káº¿t ná»‘i: {client_addr} (code: {e.code})")
    except Exception as e:
        print(f"âŒ Lá»—i WebSocket tá»« {client_addr}: {e}")
    finally:
        with connection_lock:
            if current_connection == websocket:
                current_connection = None
                print(f"ğŸ”„ ÄÃ£ giáº£i phÃ³ng káº¿t ná»‘i tá»« {client_addr}, sáºµn sÃ ng cho káº¿t ná»‘i má»›i")
        
        with audio_lock:
            current_audio_data = None
        
        with stt_lock:
            buf = stt_buffer.copy()
            stt_buffer = np.array([], dtype=np.float32)
        
        if buf.size > 0:
            buffer_to_text_and_print(buf)
        
        print(f"âœ… ÄÃ£ dá»n dáº¹p káº¿t ná»‘i tá»« {client_addr}")

# ========================
#  MAIN SERVER
# ========================
async def main():
    audio_thread = threading.Thread(target=audio_playback_loop, daemon=True)
    audio_thread.start()

    print(f"\nğŸŒ WebSocket Server: ws://0.0.0.0:8765")
    print(f"ğŸ”Š PhÃ¡t vÃ o: [{DEVICE_ID}] {sd.query_devices(DEVICE_ID)['name']}")
    print("ğŸ“± Má»Ÿ trÃ¬nh duyá»‡t â†’ káº¿t ná»‘i tá»« Ä‘iá»‡n thoáº¡i")
    print("ğŸ›‘ Ctrl+C Ä‘á»ƒ dá»«ng\n")

    async with websockets.serve(handle_audio, "0.0.0.0", 8765, ping_interval=20, ping_timeout=10):
        await asyncio.Future()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ›‘ ÄÃ£ dá»«ng server")
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        import traceback
        traceback.print_exc()
    
