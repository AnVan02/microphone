# mic_bridge.py
import asyncio
import websockets
import numpy as np
import sounddevice as sd
import threading
import time
import os
import wave
import queue

# ========================
#  C·∫§U H√åNH
# ========================
SAMPLE_RATE = 48000
CHANNELS = 1
BUFFER_SIZE = int(os.getenv('MIC_BRIDGE_BUFFER', '512'))
VERBOSE = os.getenv('MIC_BRIDGE_VERBOSE', '1') == '1'
last_print_time = time.time()

# ========================
#  IN DANH S√ÅCH THI·∫æT B·ªä
# ========================
print("Danh s√°ch thi·∫øt b·ªã √¢m thanh:\n")
for i, d in enumerate(sd.query_devices()):
    marker = " (VB-CABLE)" if 'cable' in d['name'].lower() else ""
    print(f"[{i}] {d['name']}{marker}")
    print(f"    Input: {d['max_input_channels']} | Output: {d['max_output_channels']}\n")

# ========================
#  CH·ªåN VB-CABLE T·ª∞ ƒê·ªòNG
# ========================
# GI·∫¢I TH√çCH C√ÅCH VB-CABLE HO·∫†T ƒê·ªòNG:
# - VB-CABLE l√† m·ªôt "c√°p ·∫£o" (virtual cable) ho·∫°t ƒë·ªông nh∆∞: Input ‚Üí Output
# - Code Python PH√ÅT audio v√†o "CABLE Input" (ƒë·∫ßu v√†o c·ªßa c√°p ·∫£o)
# - Chrome/Windows CH·ªåN "CABLE Output" (ƒë·∫ßu ra c·ªßa c√°p ·∫£o) l√†m microphone
# - Lu·ªìng: Python ‚Üí CABLE Input ‚Üí CABLE Output ‚Üí Chrome/tr√¨nh duy·ªát 
# - ƒê√¢y l√† c√°ch VB-CABLE ƒë∆∞·ª£c thi·∫øt k·∫ø: Input nh·∫≠n audio, Output ph√°t ra audio ƒë√≥
def find_vb_cable():
    devices = sd.query_devices()
    for i, d in enumerate(devices):
        name = d['name'].lower()
        # T√¨m "CABLE Input" v√¨ ƒë√¢y l√† n∆°i Python s·∫Ω PH√ÅT audio v√†o
        if 'cable input' in name and d['max_output_channels'] > 0:
            return i
    return 4  # Default n·∫øu kh√¥ng t√¨m th·∫•y

DEVICE_ID = find_vb_cable()
device_name = sd.query_devices(DEVICE_ID)['name']
print(f"\n{'='*60}")
print(f"H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:")
print(f"{'='*60}")
print(f"üì§ Python ph√°t audio v√†o: CABLE Input (device {DEVICE_ID})")
print(f"üì• Chrome ch·ªçn l√†m mic: CABLE Output")
print(f"\nC√°ch ho·∫°t ƒë·ªông:")
print(f"  Python ‚Üí CABLE Input ‚Üí CABLE Output ‚Üí Chrome/tr√¨nh duy·ªát ")
print(f"\nC√°c b∆∞·ªõc:")
print(f"1. Code n√†y ph√°t audio v√†o: {device_name}")
print(f"2. Trong Chrome: Click üîí ‚Üí ch·ªçn 'CABLE Output' l√†m microphone")
print(f"3. M·ªü tr√¨nh duy·ªát  ‚Üí cho ph√©p microphone ‚Üí ch·ªçn 'CABLE Output'")
print(f"4. N√≥i tr√™n ƒëi·ªán tho·∫°i ‚Üí tr√¨nh duy·ªát  s·∫Ω nh·∫≠n ƒë∆∞·ª£c!")
print(f"{'='*60}")
print(f"‚úÖ ƒê√£ ch·ªçn: [{DEVICE_ID}] {device_name}")

# Ki·ªÉm tra thi·∫øt b·ªã
try:
    test_data = np.zeros(512, dtype=np.float32)
    sd.play(test_data, samplerate=SAMPLE_RATE, device=DEVICE_ID, blocking=False)
    sd.stop()
    print("Thi·∫øt b·ªã √¢m thanh ho·∫°t ƒë·ªông t·ªët")
except Exception as e:
    print(f"L·ªói thi·∫øt b·ªã: {e}")
    exit(1)

# ========================
#  BI·∫æN TO√ÄN C·ª§C
# ========================
audio_queue = queue.Queue(maxsize=10)  # Queue ƒë·ªÉ l∆∞u audio chunks
is_playing = False
audio_lock = threading.Lock()
SAVE_INCOMING = os.getenv('MIC_BRIDGE_SAVE', '0') == '1'
SAVE_SECONDS = 4
_save_samples_threshold = SAVE_SECONDS * SAMPLE_RATE
_incoming_chunks = []
_save_lock = threading.Lock()
_saved_incoming = False
_last_audio_time = time.time()

# ========================
#  T·ªêI ∆ØU √ÇM THANH
# ========================
def optimize_audio_quality(audio_data):
    audio_data = audio_data.astype(np.float32)
    max_val = np.max(np.abs(audio_data))
    
    # TƒÉng √¢m l∆∞·ª£ng n·∫øu qu√° nh·ªè (quan tr·ªçng cho speech recognition)
    if max_val < 0.05:
        # √Çm thanh r·∫•t nh·ªè, tƒÉng m·∫°nh
        audio_data = np.clip(audio_data * 4.0, -1.0, 1.0)
    elif max_val < 0.15:
        # √Çm thanh nh·ªè, tƒÉng v·ª´a
        audio_data = np.clip(audio_data * 2.5, -1.0, 1.0)
    elif max_val < 0.4:
        # √Çm thanh trung b√¨nh, tƒÉng nh·∫π
        audio_data = np.clip(audio_data * 1.3, -1.0, 1.0)
    
    # Normalize ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng t·ªët cho speech recognition
    new_max = np.max(np.abs(audio_data))
    if new_max > 0.01 and new_max < 0.7:
        # TƒÉng ƒë·∫øn m·ª©c t·ªëi ∆∞u cho speech (kh√¥ng qu√° l·ªõn ƒë·ªÉ tr√°nh distortion)
        target_max = 0.75
        audio_data = np.clip(audio_data * (target_max / new_max), -1.0, 1.0)
    
    return audio_data

# ========================
#  V√íNG L·∫∂P PH√ÅT √ÇM THANH
# ========================
def audio_playback_loop():
    global is_playing, last_print_time
    print("B·∫Øt ƒë·∫ßu ph√°t √¢m thanh v√†o VB-CABLE Input...")
    print("(Audio s·∫Ω ch·∫£y t·ª´ CABLE Input ‚Üí CABLE Output ‚Üí Chrome)")
    try:
        with sd.OutputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=np.float32,
            device=DEVICE_ID,
            blocksize=BUFFER_SIZE,
            latency='low'
        ) as stream:
            print("Stream s·∫µn s√†ng")
            print("ƒêang ch·ªù audio t·ª´ WebSocket...")
            while True:
                try:
                    # L·∫•y audio t·ª´ queue (blocking v·ªõi timeout ng·∫Øn)
                    try:
                        audio_data = audio_queue.get(timeout=0.1)
                        if audio_data is not None and len(audio_data) > 0:
                            try:
                                optimized = optimize_audio_quality(audio_data)
                                audio_to_play = optimized.reshape(-1, 1)
                                
                                # Chia nh·ªè th√†nh c√°c chunk ƒë·ªÉ ph√°t li√™n t·ª•c
                                chunk_size = BUFFER_SIZE
                                for i in range(0, len(audio_to_play), chunk_size):
                                    chunk = audio_to_play[i:i+chunk_size]
                                    
                                    # Pad n·∫øu thi·∫øu
                                    if len(chunk) < chunk_size:
                                        padding = np.zeros((chunk_size - len(chunk), 1), dtype=np.float32)
                                        chunk = np.vstack([chunk, padding])
                                    
                                    stream.write(chunk.astype(np.float32))
                                
                                is_playing = True
                                if VERBOSE and time.time() - last_print_time >= 2.0:
                                    max_amp = np.max(np.abs(audio_to_play))
                                    status = "‚úÖ T·ªët" if max_amp > 0.1 else "‚ö†Ô∏è Nh·ªè" if max_amp > 0.01 else "‚ùå Im l·∫∑ng"
                                    queue_size = audio_queue.qsize()
                                    print(f"Ph√°t: {len(audio_to_play)} m·∫´u, max: {max_amp:.4f} {status} | Queue: {queue_size}")
                                    last_print_time = time.time()
                            except Exception as e:
                                print(f"L·ªói ph√°t: {e}")
                                is_playing = False
                    except queue.Empty:
                        # Kh√¥ng c√≥ audio m·ªõi, ph√°t silence ng·∫Øn ƒë·ªÉ gi·ªØ stream
                        silence = np.zeros((BUFFER_SIZE, CHANNELS), dtype=np.float32)
                        stream.write(silence)
                        is_playing = False
                        
                except Exception as e:
                    print(f"L·ªói trong playback loop: {e}")
                    time.sleep(0.01)
    except Exception as e:
        print(f"L·ªói stream: {e}")

# ========================
#  WEBSOCKET HANDLER
# ========================
async def handle_audio(websocket):
    global _incoming_chunks, _saved_incoming, last_print_time, _last_audio_time
    client_addr = websocket.remote_address
    print(f"‚úÖ Client k·∫øt n·ªëi: {client_addr}")
    print("ƒêang ch·ªù audio t·ª´ client...")

    try:
        async for message in websocket:
            try:
                audio_data = np.frombuffer(message, dtype=np.float32)
                
                # X·ª≠ l√Ω c·∫£ mono v√† stereo (n·∫øu c√≥)
                if len(audio_data) > 0:
                    # N·∫øu s·ªë l∆∞·ª£ng m·∫´u ch·∫µn, c√≥ th·ªÉ l√† stereo interleaved
                    if len(audio_data) % 2 == 0:
                        left_channel = audio_data[::2]
                        right_channel = audio_data[1::2]
                        # N·∫øu k√™nh ph·∫£i to√†n l√† 0 ho·∫∑c gi·ªëng h·ªát k√™nh tr√°i, th√¨ l√† mono
                        if np.max(np.abs(right_channel)) < 0.001 or np.allclose(left_channel, right_channel, atol=0.01):
                            audio_data = left_channel  # L·∫•y mono
                        else:
                            # L√† stereo th·∫≠t, ch·ªâ l·∫•y k√™nh tr√°i (ƒëi·ªán tho·∫°i)
                            audio_data = left_channel
                
                # ƒê·∫£m b·∫£o audio_data l√† 1D array
                if len(audio_data.shape) > 1:
                    audio_data = audio_data.flatten()
                
                # Log th√¥ng tin audio
                max_amplitude = np.max(np.abs(audio_data))
                _last_audio_time = time.time()
                
                if VERBOSE and time.time() - last_print_time >= 2.0:
                    status = "‚úÖ C√≥ √¢m thanh" if max_amplitude > 0.01 else "‚ö†Ô∏è Im l·∫∑ng"
                    queue_size = audio_queue.qsize()
                    print(f"üì• Nh·∫≠n: {len(audio_data)} m·∫´u, √¢m l∆∞·ª£ng: {max_amplitude:.4f} {status} | Queue: {queue_size}")
                    last_print_time = time.time()

                # Th√™m v√†o queue (b·ªè qua n·∫øu queue ƒë·∫ßy ƒë·ªÉ tr√°nh delay)
                try:
                    audio_queue.put_nowait(audio_data)
                except queue.Full:
                    # Queue ƒë·∫ßy, b·ªè qua chunk c≈© v√† th√™m m·ªõi
                    try:
                        audio_queue.get_nowait()  # B·ªè chunk c≈©
                        audio_queue.put_nowait(audio_data)  # Th√™m chunk m·ªõi
                    except:
                        pass

                # L∆∞u ƒë·ªÉ debug
                if SAVE_INCOMING and not _saved_incoming:
                    with _save_lock:
                        chunk = audio_data.copy()
                        _incoming_chunks.append(chunk)
                        total = sum(len(c) for c in _incoming_chunks)
                        if total >= _save_samples_threshold:
                            combined = np.concatenate(_incoming_chunks)
                            combined = np.clip(combined, -1.0, 1.0)
                            int_data = (combined * 32767).astype('<i2')
                            with wave.open('incoming_debug.wav', 'wb') as wf:
                                wf.setnchannels(1)
                                wf.setsampwidth(2)
                                wf.setframerate(SAMPLE_RATE)
                                wf.writeframes(int_data.tobytes())
                            print("üíæ ƒê√£ l∆∞u: incoming_debug.wav")
                            _saved_incoming = True
            except Exception as e:
                print(f"‚ùå L·ªói x·ª≠ l√Ω audio: {e}")
                import traceback
                traceback.print_exc()
    except websockets.exceptions.ConnectionClosed:
        print(f"‚ö†Ô∏è Client ng·∫Øt k·∫øt n·ªëi: {client_addr}")
    except Exception as e:
        print(f"‚ùå L·ªói WebSocket: {e}")
    finally:
        # X√≥a queue khi ng·∫Øt k·∫øt n·ªëi
        while not audio_queue.empty():
            try:
                audio_queue.get_nowait()
            except:
                break
        print("üßπ ƒê√£ d·ªçn d·∫πp k·∫øt n·ªëi")

# ========================
#  MAIN SERVER
# ========================
async def main():
    audio_thread = threading.Thread(target=audio_playback_loop, daemon=True)
    audio_thread.start()

    print(f"\nWebSocket Server: ws://0.0.0.0:8765")
    print(f"Ph√°t v√†o: [{DEVICE_ID}] {sd.query_devices(DEVICE_ID)['name']}")
    print("M·ªü tr√¨nh duy·ªát ‚Üí k·∫øt n·ªëi t·ª´ ƒëi·ªán tho·∫°i")
    print("Ctrl+C ƒë·ªÉ d·ª´ng\n")

    async with websockets.serve(handle_audio, "0.0.0.0", 8765, ping_interval=20, ping_timeout=10):
        await asyncio.Future()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nƒê√£ d·ª´ng server")
    except Exception as e:
        print(f"L·ªói: {e}")
        import traceback
        traceback.print_exc()