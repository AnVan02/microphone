#!/usr/bin/env python3
# mic_bridge_fixed.py
# Cáº£i tiáº¿n cho mic_bridge.py:
# - DÃ¹ng queue (deque) thay vÃ¬ ghi Ä‘Ã¨ current_audio_data
# - TÄƒng BUFFER máº·c Ä‘á»‹nh
# - Chuyá»ƒn vÃ  chuáº©n hoÃ¡ Float32 -> int16 trÆ°á»›c khi phÃ¡t Ä‘á»ƒ Chrome/VB-Cable nháº­n tá»‘t
# - ThÃªm tÃ¹y chá»n lÆ°u incoming_debug.wav (MIC_BRIDGE_SAVE=1)
# - In log rÃµ rÃ ng hÆ¡n
import asyncio
import websockets
import numpy as np
import sounddevice as sd
import threading
import time
import os
import wave
from collections import deque

# ========================
#  Cáº¤U HÃŒNH
# ========================
SAMPLE_RATE = 48000
CHANNELS = 1
BUFFER_SIZE = int(os.getenv('MIC_BRIDGE_BUFFER', '1024'))  # tÄƒng buffer
VERBOSE = os.getenv('MIC_BRIDGE_VERBOSE', '1') == '1'
last_print_time = time.time()

# ========================
#  IN DANH SÃCH THIáº¾T Bá»Š
# ========================
print("ğŸ§ Danh sÃ¡ch thiáº¿t bá»‹ Ã¢m thanh:\n")
for i, d in enumerate(sd.query_devices()):
    marker = ""
    if 'cable' in d['name'].lower():
        marker = " â­ VB-CABLE"
    print(f"[{i}] {d['name']}")
    print(f"    ğŸ“¥ Input: {d['max_input_channels']} | ğŸ“¤ Output: {d['max_output_channels']}{marker}\n")

# ========================
#  CHá»ŒN DEVICE Tá»° Äá»˜NG
# ========================
def find_vb_cable():
    devices = sd.query_devices()
    for i, d in enumerate(devices):
        name = d['name']
        if 'cable input' in name.lower() and d['max_output_channels'] > 0:
            return i
    return None

DEVICE_ID = find_vb_cable()
if DEVICE_ID is None:
    # Fallback: try find any device with 'cable' in name
    for i, d in enumerate(sd.query_devices()):
        if 'cable' in d['name'].lower():
            DEVICE_ID = i
            break

if DEVICE_ID is None:
    print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y VB-Cable. Vui lÃ²ng cÃ i Ä‘áº·t VB-Audio Virtual Cable vÃ  thá»­ láº¡i.")
    # nhÆ°ng khÃ´ng exit, Ä‘á»ƒ user cÃ³ thá»ƒ chá»n thá»§ cÃ´ng
    DEVICE_ID = int(os.getenv('MIC_BRIDGE_DEVICE', '4'))

print(f"\nğŸ’¡ HÆ¯á»šNG DáºªN:")
print(f"1. Script nÃ y sáº½ phÃ¡t Ã¢m thanh vÃ o device id = {DEVICE_ID}")
try:
    print(f"   Thiáº¿t bá»‹ Ä‘Æ°á»£c chá»n: [{DEVICE_ID}] {sd.query_devices(DEVICE_ID)['name']}")
except Exception:
    print("   KhÃ´ng thá»ƒ láº¥y tÃªn device - kiá»ƒm tra DEVICE_ID báº±ng tay náº¿u cáº§n.")

# Kiá»ƒm tra thiáº¿t bá»‹
try:
    test_data = np.zeros(512, dtype=np.float32)
    sd.play(test_data, samplerate=SAMPLE_RATE, device=DEVICE_ID, blocking=False)
    sd.stop()
    print("âœ… Thiáº¿t bá»‹ Ã¢m thanh hoáº¡t Ä‘á»™ng tá»‘t (test play)")
except Exception as e:
    print(f"âŒ Lá»—i thiáº¿t bá»‹ Ã¢m thanh: {e}")
    # khÃ´ng exit, váº«n cho phÃ©p debug

# ========================
#  BIáº¾N TOÃ€N Cá»¤C (QUEUE)
# ========================
audio_queue = deque(maxlen=400)  # queue chá»©a cÃ¡c chunk float32
is_playing = False
audio_lock = threading.Lock()
SAVE_INCOMING = os.getenv('MIC_BRIDGE_SAVE', '0') == '1'
SAVE_SECONDS = int(os.getenv('MIC_BRIDGE_SAVE_SECONDS', '4'))
_save_samples_threshold = SAVE_SECONDS * SAMPLE_RATE
_incoming_chunks = []
_save_lock = threading.Lock()
_saved_incoming = False

# ========================
#  Tá»I Æ¯U HÃ“A Ã‚M THANH
# ========================
def optimize_audio_quality(audio_data):
    audio_data = audio_data.astype(np.float32)
    max_val = np.max(np.abs(audio_data)) if audio_data.size>0 else 0.0
    if max_val < 0.1:
        audio_data = np.clip(audio_data * 1.5, -1.0, 1.0)
    return audio_data

# ========================
#  VÃ’NG Láº¶P PHÃT Ã‚M THANH (Ä‘á»c tá»« queue)
# ========================
def audio_playback_loop():
    global is_playing, last_print_time, _saved_incoming
    print("ğŸ”Š Báº¯t Ä‘áº§u vÃ²ng láº·p phÃ¡t Ã¢m thanh...")
    try:
        with sd.OutputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=np.float32,
            device=DEVICE_ID,
            blocksize=BUFFER_SIZE,
            latency='low'
        ) as stream:
            print("âœ… Audio stream Ä‘Ã£ sáºµn sÃ ng")
            while True:
                to_play = None
                with audio_lock:
                    if len(audio_queue) > 0:
                        to_play = audio_queue.popleft()

                if to_play is not None and to_play.size > 0:
                    try:
                        optimized = optimize_audio_quality(to_play)
                        # Ä‘áº£m báº£o mono column vector
                        if optimized.ndim == 1:
                            audio_arr = optimized.reshape(-1, 1)
                        else:
                            audio_arr = optimized[:, 0].reshape(-1, 1)

                        # Convert float32 (-1..1) -> int16 -> back to float32 normalized
                        clipped = np.clip(audio_arr, -1.0, 1.0)
                        int16 = (clipped * 32767).astype('<i2')   # little-endian int16
                        audio_to_play = (int16.astype(np.float32) / 32767.0).astype(np.float32)
                        # ensure shape (N,1)
                        if audio_to_play.ndim == 1:
                            audio_to_play = audio_to_play.reshape(-1, 1)

                        stream.write(audio_to_play)
                        is_playing = True
                        if VERBOSE and time.time() - last_print_time >= 2.0:
                            print(f"ğŸ“¤ PhÃ¡t audio: {audio_to_play.shape[0]} samples, max: {np.max(np.abs(audio_to_play)):.4f}")
                            last_print_time = time.time()
                    except Exception as e:
                        print(f"âš ï¸ Lá»—i khi phÃ¡t audio: {e}")
                        is_playing = False
                else:
                    # phÃ¡t silence náº¿u queue rá»—ng
                    silence = np.zeros((BUFFER_SIZE, CHANNELS), dtype=np.float32)
                    try:
                        stream.write(silence)
                    except Exception:
                        pass
                    is_playing = False

                time.sleep(0.001)
    except Exception as e:
        print(f"âŒ Lá»—i audio stream: {e}")
        import traceback
        traceback.print_exc()

# ========================
#  WEBSOCKET HANDLER
# ========================
async def handle_audio(websocket):
    global _incoming_chunks, _saved_incoming
    client_addr = websocket.remote_address
    print(f"âœ… Client Ä‘Ã£ káº¿t ná»‘i tá»« {client_addr}")

    try:
        async for message in websocket:
            try:
                # message lÃ  binary Float32Array (little-endian)
                audio_data = np.frombuffer(message, dtype=np.float32)
                if audio_data.size == 0:
                    continue

                # debug print
                if VERBOSE and time.time() - last_print_time >= 2.0:
                    print(f"ğŸ“¥ Nháº­n audio: {audio_data.shape[0]} samples, max: {np.max(np.abs(audio_data)):.4f}")

                # Ä‘áº£m báº£o mono 1d
                if audio_data.ndim > 1:
                    audio_data = audio_data[:, 0]

                # push vÃ o queue
                with audio_lock:
                    audio_queue.append(audio_data.copy())

                # LÆ°u incoming Ä‘á»ƒ debug náº¿u báº­t
                if SAVE_INCOMING and not _saved_incoming:
                    with _save_lock:
                        _incoming_chunks.append(audio_data.copy())
                        total = sum(c.shape[0] for c in _incoming_chunks)
                        if total >= _save_samples_threshold:
                            combined = np.concatenate(_incoming_chunks)
                            combined = np.clip(combined, -1.0, 1.0)
                            int_data = (combined * 32767).astype('<i2')
                            with wave.open('incoming_debug.wav', 'wb') as wf:
                                wf.setnchannels(1)
                                wf.setsampwidth(2)
                                wf.setframerate(SAMPLE_RATE)
                                wf.writeframes(int_data.tobytes())
                            print(f"âœ… ÄÃ£ lÆ°u incoming audio: incoming_debug.wav ({total} samples)")
                            _saved_incoming = True
            except Exception as e:
                print(f"âš ï¸ Lá»—i xá»­ lÃ½ message: {e}")
    except websockets.exceptions.ConnectionClosed:
        print(f"âŒ Client {client_addr} Ä‘Ã£ ngáº¯t káº¿t ná»‘i")
    except Exception as e:
        print(f"âŒ Lá»—i WebSocket: {e}")
    finally:
        print(f"ğŸ§¹ Dá»n dáº¹p káº¿t ná»‘i tá»« {client_addr}")

# ========================
#  MAIN SERVER
# ========================
async def main():
    # Báº¯t Ä‘áº§u thread phÃ¡t audio
    audio_thread = threading.Thread(target=audio_playback_loop, daemon=True)
    audio_thread.start()

    print(f"\nğŸ™ï¸ WebSocket Server Ä‘ang cháº¡y táº¡i ws://0.0.0.0:8765")
    try:
        print(f"ğŸ”Š PhÃ¡t audio vÃ o device: [{DEVICE_ID}] {sd.query_devices(DEVICE_ID)['name']}")
    except Exception:
        print("ğŸ”Š KhÃ´ng xÃ¡c Ä‘á»‹nh tÃªn device")

    print("ğŸ“± HÃ£y má»Ÿ trÃ¬nh duyá»‡t vÃ  káº¿t ná»‘i...")
    print("â¹ï¸ Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng server\n")

    # Khá»Ÿi Ä‘á»™ng WebSocket server
    async with websockets.serve(
        handle_audio,
        "0.0.0.0",
        8765,
        ping_interval=20,
        ping_timeout=10
    ):
        await asyncio.Future()

    print("Ä‘ang dá»«ng server")
if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ›‘ Äang dá»«ng server...")
    except Exception as e:
        print(f"âŒ Lá»—i khÃ´ng mong muá»‘n: {e}")
    