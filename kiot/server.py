import asyncio
import websockets
import numpy as np
import sounddevice as sd
import threading
import time
import os
import wave
from scipy import signal

# ========================
#  C·∫§U H√åNH
# ========================
SAMPLE_RATE = 48000
CHANNELS = 1
BUFFER_SIZE = 2048  # ‚úÖ TƒÉng buffer size
VERBOSE = os.getenv('MIC_BRIDGE_VERBOSE', '1') == '1'
last_print_time = time.time()

# ========================
#  IN DANH S√ÅCH THI·∫æT B·ªä
# ========================
print("üéß Danh s√°ch thi·∫øt b·ªã √¢m thanh:\n")
for i, d in enumerate(sd.query_devices()):
    marker = ""
    if 'cable' in d['name'].lower():
        marker = " ‚≠ê VB-CABLE"
    print(f"[{i}] {d['name']}")
    print(f"    üì• Input: {d['max_input_channels']} | üì§ Output: {d['max_output_channels']}{marker}\n")

# ========================
#  CH·ªåN DEVICE T·ª∞ ƒê·ªòNG
# ========================
def find_vb_cable():
    """T√¨m VB-Cable Input (ID=4) - thi·∫øt b·ªã output ƒë·ªÉ ph√°t √¢m thanh v√†o"""
    devices = sd.query_devices()
    for i, d in enumerate(devices):
        name = d['name']
        if 'cable input' in name.lower() and d['max_output_channels'] > 0:
            return i
    return 4

DEVICE_ID = find_vb_cable()
print(f"\nüí° H∆Ø·ªöNG D·∫™N:")
print(f"1. Script n√†y s·∫Ω ph√°t √¢m thanh v√†o: CABLE Input (device {DEVICE_ID})")
print(f"2. Trong Chrome/Windows: ch·ªçn 'CABLE Output' l√†m microphone")
print(f"‚úÖ T·ª± ƒë·ªông ch·ªçn device [{DEVICE_ID}] {sd.query_devices(DEVICE_ID)['name']}")

# Ki·ªÉm tra thi·∫øt b·ªã
try:
    test_data = np.zeros(512, dtype=np.float32)
    sd.play(test_data, samplerate=SAMPLE_RATE, device=DEVICE_ID, blocking=False)
    sd.stop()
    print("‚úÖ Thi·∫øt b·ªã √¢m thanh ho·∫°t ƒë·ªông t·ªët")
except Exception as e:
    print(f"‚ùå L·ªói thi·∫øt b·ªã √¢m thanh: {e}")
    exit(1)

# ========================
#  BI·∫æN TO√ÄN C·ª§C
# ========================
current_audio_data = None
is_playing = False
audio_lock = threading.Lock()
SAVE_INCOMING = os.getenv('MIC_BRIDGE_SAVE', '0') == '1'
SAVE_SECONDS = int(os.getenv('MIC_BRIDGE_SAVE_SECONDS', '4'))
_save_samples_threshold = SAVE_SECONDS * SAMPLE_RATE
_incoming_chunks = []
_save_lock = threading.Lock()
_saved_incoming = False

# ========================
#  T·ªêI ∆ØU H√ìA √ÇM THANH
# ========================
def optimize_audio_quality(audio_data):
    """T·ªëi ∆∞u h√≥a ch·∫•t l∆∞·ª£ng √¢m thanh cho speech recognition"""
    audio_data = audio_data.astype(np.float32)
    
    # ‚úÖ Normalize √¢m l∆∞·ª£ng
    max_val = np.max(np.abs(audio_data)) if audio_data.size > 0 else 0.0
    if max_val > 0.01:  # Tr√°nh chia cho 0
        audio_data = audio_data / max_val * 0.8  # Normalize v·ªÅ 80%
    
    # ‚úÖ Boost n·∫øu qu√° nh·ªè
    if max_val < 0.1:
        audio_data = np.clip(audio_data * 2.0, -1.0, 1.0)
    
    return audio_data

# ========================
#  X·ª¨ L√ù AUDIO LI√äN T·ª§C
# ========================
def audio_playback_loop():
    """V√≤ng l·∫∑p ph√°t √¢m thanh li√™n t·ª•c"""
    global current_audio_data, is_playing, last_print_time
    
    print("üìä B·∫Øt ƒë·∫ßu v√≤ng l·∫∑p ph√°t √¢m thanh...")
    
    try:
        with sd.OutputStream(
            samplerate=SAMPLE_RATE,
            channels=CHANNELS,
            dtype=np.float32,
            device=DEVICE_ID,
            blocksize=BUFFER_SIZE,
            latency='low'
        ) as stream:
            
            print("‚úÖ Audio stream ƒë√£ s·∫µn s√†ng")
            
            while True:
                with audio_lock:
                    if current_audio_data is not None and len(current_audio_data) > 0:
                        try:
                            # T·ªëi ∆∞u h√≥a ch·∫•t l∆∞·ª£ng √¢m thanh
                            optimized_audio = optimize_audio_quality(current_audio_data)
                            
                            # ƒê·∫£m b·∫£o d·ªØ li·ªáu l√† mono
                            if optimized_audio.ndim == 1:
                                audio_to_play = optimized_audio.reshape(-1, 1)
                            else:
                                audio_to_play = optimized_audio[:, 0].reshape(-1, 1)
                            
                            stream.write(audio_to_play.astype(np.float32))
                            is_playing = True
                            
                            if VERBOSE and time.time() - last_print_time >= 2.0:
                                print(f"üì§ Ph√°t audio: {len(audio_to_play)} samples, max: {np.max(np.abs(audio_to_play)):.4f}")
                                last_print_time = time.time()
                        except Exception as e:
                            print(f"‚ö†Ô∏è L·ªói ph√°t audio: {e}")
                            is_playing = False
                    else:
                        silence = np.zeros((BUFFER_SIZE, CHANNELS), dtype=np.float32)
                        stream.write(silence)
                        is_playing = False
                
                time.sleep(0.001)
                
    except Exception as e:
        print(f"‚ùå L·ªói audio stream: {e}")
        import traceback
        traceback.print_exc()

# ========================
#  WEBSOCKET HANDLER
# ========================
async def handle_audio(websocket):
    """X·ª≠ l√Ω k·∫øt n·ªëi WebSocket v√† nh·∫≠n audio data"""
    global current_audio_data, _incoming_chunks, _saved_incoming, last_print_time
    
    client_addr = websocket.remote_address
    print(f"‚úÖ Client ƒë√£ k·∫øt n·ªëi t·ª´ {client_addr}")
    
    try:
        async for message in websocket:
            try:
                # Chuy·ªÉn ƒë·ªïi binary message th√†nh numpy array
                raw_data = np.frombuffer(message, dtype=np.float32)
                
                # ‚úÖ X·ª¨ L√ù STEREO -> MONO
                if len(raw_data) % 2 == 0:  # Stereo format: LRLRLR...
                    # T√°ch left (phone) v√† right (PC mic)
                    left_channel = raw_data[0::2]   # Remote/phone audio
                    right_channel = raw_data[1::2]  # Local PC mic (kh√¥ng d√πng)
                    
                    audio_data = left_channel  # ‚úÖ Ch·ªâ l·∫•y phone audio
                    
                    if VERBOSE and time.time() - last_print_time >= 2.0:
                        print(f"üìä Stereo->Mono: Left={len(left_channel)}, Right={len(right_channel)}")
                else:
                    audio_data = raw_data
                
                # Debug info
                max_amplitude = np.max(np.abs(audio_data))
                print(f"üì• Nh·∫≠n audio: {len(audio_data)} samples, √¢m l∆∞·ª£ng: {max_amplitude:.4f}")
                
                # C·∫≠p nh·∫≠t audio data ƒë·ªÉ ph√°t
                with audio_lock:
                    current_audio_data = audio_data

                # L∆∞u audio ƒë·ªÉ debug (n·∫øu c·∫ßn)
                if SAVE_INCOMING and not _saved_incoming:
                    try:
                        with _save_lock:
                            chunk = audio_data if audio_data.ndim == 1 else audio_data[:, 0]
                            _incoming_chunks.append(chunk.copy())
                            total = sum(c.shape[0] for c in _incoming_chunks)
                            
                            if total >= _save_samples_threshold:
                                combined = np.concatenate(_incoming_chunks)
                                combined = np.clip(combined, -1.0, 1.0)
                                int_data = (combined * 32767).astype('<i2')
                                
                                with wave.open('incoming_debug.wav', 'wb') as wf:
                                    wf.setnchannels(1)
                                    wf.setsampwidth(2)
                                    wf.setframerate(SAMPLE_RATE)
                                    wf.writeframes(int_data.tobytes())
                                
                                print(f"‚úÖ ƒê√£ l∆∞u incoming audio: incoming_debug.wav")
                                _saved_incoming = True
                    except Exception as e:
                        print(f"‚ö†Ô∏è L·ªói khi l∆∞u audio: {e}")
                        
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω message: {e}")
                
    except websockets.exceptions.ConnectionClosed:
        print(f"‚ùå Client {client_addr} ƒë√£ ng·∫Øt k·∫øt n·ªëi")
    except Exception as e:
        print(f"‚ùå L·ªói WebSocket: {e}")
    finally:
        # Reset audio khi client disconnect
        with audio_lock:
            current_audio_data = None
        print(f"üßπ ƒê√£ d·ªçn d·∫πp k·∫øt n·ªëi t·ª´ {client_addr}")

# ========================
#  MAIN SERVER
# ========================
async def main():
    """Kh·ªüi ƒë·ªông server WebSocket v√† audio playback"""
    # B·∫Øt ƒë·∫ßu thread ph√°t audio
    audio_thread = threading.Thread(target=audio_playback_loop, daemon=True)
    audio_thread.start()
    
    print(f"\nüéôÔ∏è WebSocket Server ƒëang ch·∫°y t·∫°i ws://0.0.0.0:8765")
    print(f"üìä Ph√°t audio v√†o device: [{DEVICE_ID}] {sd.query_devices(DEVICE_ID)['name']}")
    print("üì± H√£y m·ªü tr√¨nh duy·ªát v√† k·∫øt n·ªëi...")
    print("‚ÑπÔ∏è Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng server\n")
    
    # Kh·ªüi ƒë·ªông WebSocket server
    async with websockets.serve(
        handle_audio, 
        "0.0.0.0", 
        8765,
        ping_interval=20,
        ping_timeout=10
    ):
        await asyncio.Future()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüëã ƒê√£ d·ª´ng server")
    except Exception as e:
        print(f"\n‚ùå L·ªói kh√¥ng mong mu·ªën: {e}")
        import traceback
        traceback.print_exc()